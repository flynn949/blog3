hist(students$first_session_marks, breaks = 15)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
aptitude_markscale <- meanmark + aptitude*marks_sd
students <- data.frame(aptitude, aptitude_markscale)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
hist(students$first_session_marks, breaks = 15)
max(students$first_session_marks)
beta_0 <- 1
beta_1 <- 0.9
beta_2 <- 5
sigma <- 5
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude_markscale + beta_2*students$tutored
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
aptitude_markscale <- meanmark + aptitude*marks_sd
students <- data.frame(aptitude, aptitude_markscale)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for soem values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 1
beta_1 <- 0.9
beta_2 <- 5
sigma <- 5
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude_markscale + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
aptitude_markscale <- meanmark + aptitude*marks_sd
students <- data.frame(aptitude, aptitude_markscale)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for soem values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 1
beta_1 <- 0.9
beta_2 <- 5
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude_markscale + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
aptitude_markscale <- meanmark + aptitude*marks_sd
students <- data.frame(aptitude, aptitude_markscale)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for soem values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
meanmark_secondsession <- 58
beta_0 <- 1
beta_1 <- 0.9
beta_2 <- 5
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + meanmark_secondsession + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
aptitude_markscale <- meanmark + aptitude*marks_sd
students <- data.frame(aptitude, aptitude_markscale)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for soem values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 5
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
meanmark - beta_0
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
students <- data.frame(aptitude)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for soem values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 7
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, beta3, sigma_secondsession, beta0 = 2, beta1 = 0.9){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
aptitude_markscale <- meanmark + aptitude*marks_sd
first_session <- rnorm(nstudents, aptitude_markscale, 2)
second_session <- beta0 + beta1*aptitude_markscale + rnorm(nstudents, 0, sigma_secondsession)
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
second_session[tutored.indices] <- second_session[tutored.indices] + beta3
lmod <- summary(lm(second_session ~ first_session + tutored))
return(lmod$coefficients[3,4]) #The pvalue for the beta3 estimate.
}
pvals <- replicate(10000, power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 5))
mean(pvals <= 0.05)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
students <- data.frame(aptitude)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for soem values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ 1 + first_session_marks + tutored, data = students)
summary(regression_model)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, beta3, sigma_secondsession, beta0 = 58, beta1 = 0.9){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
aptitude_markscale <- meanmark + aptitude*marks_sd
first_session <- rnorm(nstudents, aptitude_markscale, 2)
second_session <- beta0 + beta1*aptitude*marks_sd + rnorm(nstudents, 0, sigma_secondsession)
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
second_session <- second_session[sort(order(second_session)[first_session])]
second_session[tutored.indices] <- second_session[tutored.indices] + beta3
lmod <- summary(lm(second_session ~ first_session + tutored))
return(lmod$coefficients[3,4]) #The pvalue for the beta3 estimate.
}
pvals <- replicate(10000, power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2))
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2)
pvals <- replicate(10000, power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2))
order(c(5,8,3)[c(3,6,1)])
c(5,8,3)[order(c(5,8,3)[c(3,6,1)])]
c(5,8,3)[order(c(6,7,1)]
c(5,8,3)[order(c(6,7,1))]
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, beta3, sigma_secondsession, beta0 = 58, beta1 = 0.9){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
aptitude_markscale <- meanmark + aptitude*marks_sd
students$first_session_marks <- rnorm(nstudents, students$aptitude*12 + meanmark, 2)
students$second_session <- beta0 + beta1*aptitude*marks_sd + rnorm(nstudents, 0, sigma_secondsession)
students <- students[order(students$first_session_marks),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- students$second_session + beta3*students$tutored
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the beta3 estimate.
}
pvals <- replicate(10000, power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2))
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, beta3, sigma_secondsession, beta0 = 58, beta1 = 0.9){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
aptitude_markscale <- meanmark + aptitude*marks_sd
students$first_session <- rnorm(nstudents, students$aptitude*12 + meanmark, 2)
students$second_session <- beta0 + beta1*aptitude*marks_sd + rnorm(nstudents, 0, sigma_secondsession)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- students$second_session + beta3*students$tutored
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the beta3 estimate.
}
pvals <- replicate(10000, power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2))
mean(pvals <= 0.05)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, beta3, sigma_secondsession, beta0 = 58, beta1 = 0.9){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
aptitude_markscale <- meanmark + aptitude*marks_sd
students$first_session <- rnorm(nstudents, students$aptitude*12 + 60, 2)
students$second_session <- beta0 + beta1*aptitude*marks_sd + rnorm(nstudents, 0, sigma_secondsession)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- students$second_session + beta3*students$tutored
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the beta3 estimate.
}
pvals <- replicate(10000, power_simulation(n_tutored = 50, n_untutored = 450, beta3 = 2.4, sigma_secondsession = 2))
mean(pvals <= 0.05)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
aptitude_markscale <- meanmark + aptitude*marks_sd
students$first_session <- rnorm(nstudents, students$aptitude*12 + 60, 2)
students$second_session <- beta0 + beta1*aptitude*marks_sd + rnorm(nstudents, 0, sigma_secondsession)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- students$second_session + tutoring_effect*students$tutored
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
}
pvals <- replicate(1000, power_simulation(n_tutored = 50, n_untutored = 450, tutoring_effect = 2.4, sigma_secondsession = 2))
mean(pvals <= 0.05)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students$second_session <- beta0 + beta1*aptitude*marks_sd + rnorm(nstudents, 0, sigma_secondsession)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- students$second_session + tutoring_effect*students$tutored
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
}
pvals <- replicate(1000, power_simulation(n_tutored = 50, n_untutored = 450, tutoring_effect = 2.4, sigma_secondsession = 2))
mean(pvals <= 0.05)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- rnorm(nstudents, beta0 + beta1*aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
}
pvals <- replicate(1000, power_simulation(n_tutored = 50, n_untutored = 450, tutoring_effect = 2.4, sigma_secondsession = 2))
mean(pvals <= 0.05)
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- rnorm(nstudents, beta0 + beta1*aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(students)
#return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
}
power_simulation(n_tutored = 50, n_untutored = 450, tutoring_effect = 2.4, sigma_secondsession = 2)
test <- power_simulation(n_tutored = 50, n_untutored = 450, tutoring_effect = 2.4, sigma_secondsession = 2)
View(test)
invlogit <- function(x){1/(1+exp(-x))}
logit <- function(x){log(x/(1-x))}
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12){
nstudents <- n_tutored + n_untutored
aptitude <- sort(rnorm(nstudents, 0, 1))
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students <- students[order(students$first_session),]
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
students$second_session <- rnorm(nstudents, beta0 + beta1*aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
lmod <- summary(lm(second_session ~ first_session + tutored, data = students))
return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
}
pvals <- replicate(1000, power_simulation(n_tutored = 50, n_untutored = 450, tutoring_effect = 1, sigma_secondsession = 2))
mean(pvals <= 0.05)
