plot(seq(-7,7,0.1), yvals)
yvals <- dnorm(seq(-7,10,0.1), 1, 2) + dnorm(seq(-7,10,0.1), 2, 2)
plot(seq(-7,10,0.1), yvals)
y <- seq(-7,10,0.1)
py <- dnorm(y,1,2)+dnorm(y,2,2)
plot(y,py)
y <- seq(-7,10,0.1)
py <- 0.5*dnorm(y,1,2)+0.5*dnorm(y,2,2)
plot(y,py, type = "l")
py <- 0.5*dnorm(1,1,2)+0.5*dnorm(1,2,2)
ptheta <- 0.5
plik <- dnorm(1,1,2)
(post <- plik*ptheta/py)
shapefunc <- function(sigma){
y <- seq(-7,10,0.1)
py <- 0.5*dnorm(y,1,sigma)+0.5*dnorm(y,2,sigma)
plot(y,py, type = "l")
}
shapefunc(0.1)
shapefunc(10)
shapefunc(5)
shapefunc <- function(sigma){
y <- seq(-1*sigma*4,sigma*4,0.1)
py <- 0.5*dnorm(y,1,sigma)+0.5*dnorm(y,2,sigma)
plot(y,py, type = "l")
}
shapefunc(0.1)
shapefunc <- function(sigma){
y <- seq(-1*sigma*4,4+sigma*4,0.1)
py <- 0.5*dnorm(y,1,sigma)+0.5*dnorm(y,2,sigma)
plot(y,py, type = "l")
}
shapefunc(0.1)
shapefunc <- function(sigma){
y <- seq(-1*sigma*4,3+sigma*4,0.1)
py <- 0.5*dnorm(y,1,sigma)+0.5*dnorm(y,2,sigma)
plot(y,py, type = "l")
}
shapefunc(0.1)
shapefunc <- function(sigma){
y <- seq(-1*sigma*4,3+sigma*4,0.01)
py <- 0.5*dnorm(y,1,sigma)+0.5*dnorm(y,2,sigma)
plot(y,py, type = "l")
}
shapefunc(0.1)
shapefunc(5)
source('~/.active-rstudio-document', echo=TRUE)
hist(rth)
rth
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
rth
source('~/.active-rstudio-document', echo=TRUE)
rth
source('~/.active-rstudio-document', echo=TRUE)
rth
source('~/.active-rstudio-document', echo=TRUE)
rth2 <- recursive_random(500,89,781,387,20)
rth2
rth2 <- recursive_random(20,89,781,387,20)
rth2
rth2 <- recursive_random(20,0.5,781,387,20)
rth2
recursive_random <- function(n, seed, a, b, m){
randseq <- c()
for (i in 1:n){
randseq[[i]] <- (a*seed + b) %% m
seed <- randseq[[i]]
}
return(unlist(randseq)/m)
}
rth <- recursive_random(500,89,781,387,1000)
rthx <- rth[rep(c(0,1),250)==0]
rthy <- rth[rep(c(0,1),250)==1]
plot(rthx,rthy)
rth
g <- recursive_random(500,89,781,387,1000)
gindex <- recursive_random(20,2,781,387,20)
g[gindex[4]]
g
g[5]
gindex[4]
gindex <- recursive_random(20,2,781,387,20)
gindex
gindex <- recursive_random(20,643,781,387,20)
gindex
gindex <- recursive_random(20,643,781,387,20)*20
gindex
g[gindex[5]]
gindex[5]
g[18]
recursive_random(20,0.5,734,387,20)*20
recursive_random2 <- function(seed, nval){
vlist <- c()
for (i in 1:nval){
seed <- ((pi + seed)^5) %% 1
vlist[i] <- seed
}
}
recursive_random2(0.5,100)
recursive_random2 <- function(seed, nval){
vlist <- c()
for (i in 1:nval){
seed <- ((pi + seed)^5) %% 1
vlist[i] <- seed
}
return(vlist)
}
recursive_random2(0.5,100)
vs <- recursive_random(500,89,781,387,1000)
plot(vs[rep(c(0,1),250)==0], vs[rep(c(0,1),250)==1])
recursive_random(20,0.5,734,387,20)*20
recursive_random(20,0.5,734,387,500)*500
x <- recursive_random(500,89,781,387,1000)
gindex <- recursive_random(20,0.5,734,387,500)*500
x[gindex]
gindex
x[254]
x[413]
y <- recursive_random2(0.5,20)
y[1]
y[1]*20
x <- recursive_random(500,89,781,387,1000)
y <- recursive_random2(0.5,20)
v_index <- recursive_random(20,0.5,734,387,500)*500
v <- x[v_index]
z <- c()
20*y
x <- recursive_random(500,89,781,387,1000)
y <- recursive_random2(500,34,781,387,1000)
v_index <- recursive_random(20,0.5,734,387,500)*500
v <- x[v_index]
z <- c()
x <- recursive_random(500,89,781,387,1000)
y <- recursive_random(500,34,781,387,1000)
v_index <- recursive_random(20,0.5,734,387,500)*500
v <- x[v_index]
z <- c()
y*20
plot(x,y)
recursive_random <- function(seed, a, b, m){
return(((a*seed + b) %% m)/m))
}
recursive_random <- function(seed, a, b, m){
return(((a*seed + b) %% m)/m)
}
recursive_random(50,34,42,1000)
recursive_random(0.742,34,42,1000)
recursive_random(0.067228,34,42,1000)
recursive_random(0.04428575,34,42,1000)
recursive_random(0.04350572,34,42,1000)
recursive_random2 <- function(seed){
return(((pi + seed)^5) %% 1)
}
recursive_random2(50)
recursive_random2(5054)
recursive_random2(53)
recursive_random2(10)
recursive_random2(0.5
)
random <- function(seed, a, b, m){
return(((a*seed + b) %% m)/m)
}
random2 <- function(seed){
return(((pi + seed)^5) %% 1)
}
random2(23)
random2(0.5)
random2(0.5)
random2(0.5)
random2(0.5)
random2(0.5)
random2(23)
random2(23)
random2(23)
random2(23)
source('C:/Users/Flynn/Desktop/random_numbers.R', echo=TRUE)
source('C:/Users/Flynn/Desktop/random_numbers.R', echo=TRUE)
source('C:/Users/Flynn/Desktop/random_numbers.R', echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
students <- data.frame(aptitude)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for some values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
View(students)
View(students)
propmod <- glm(tutored ~ first_session_marks, family = "binomial", data = students)
summary(propmod)
View(students)
egstudent <- data.frame("first_session_marks" = 53)
predict(propmod, newdata = egstudent)
predict(propmod, newdata = egstudent,type = "response")
highestmark <- max(students$first_session_marks[students$tutored == 1])
highestmark <- max(students$first_session_marks[students$tutored == 1])
egstudent <- data.frame("first_session_marks" = highestmark)
predict(propmod, newdata = egstudent, type = "response")
max(students$first_session_marks[students$tutored == 1])
egstudent <- data.frame("first_session_marks" = 5)
predict(propmod, newdata = egstudent, type = "response")
egstudent <- data.frame("first_session_marks" = highestmark)
predict(propmod, newdata = egstudent, type = "response")
highestmark <- max(students$first_session_marks[students$tutored == 1])
egstudent <- data.frame("first_session_marks" = highestmark)
(lowestpropensity <- predict(propmod, newdata = egstudent, type = "response"))
students$propensity <- predict(propmod, newdata = students, type = "response")
students.subset <- students[students$propensity <= lowestpropensity,]
plot(students.subset$first_session_marks, students.subset$second_session_marks,
col = factor(students.subset$tutored, levels = c(0,1)))
students$propensity <- predict(propmod, newdata = students, type = "response")
students.subset <- students[students$propensity >= lowestpropensity,]
plot(students.subset$first_session_marks, students.subset$second_session_marks,
col = factor(students.subset$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ first_session_marks + tutored, data = students.subset)
summary(regression_model)
students$propensity <- predict(propmod, newdata = students, type = "response")
(lowestpropensity <- min(students$propensity[students$tutored==1])
students$propensity <- predict(propmod, newdata = students, type = "response")
(lowestpropensity <- min(students$propensity[students$tutored==1]))
students.subset <- students[students$propensity >= lowestpropensity,]
plot(students.subset$first_session_marks, students.subset$second_session_marks,
col = factor(students.subset$tutored, levels = c(0,1)))
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
students <- data.frame(aptitude)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for some values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
propmod <- glm(tutored ~ first_session_marks, family = "binomial", data = students)
summary(propmod)
students$propensity <- predict(propmod, newdata = students, type = "response")
(lowestpropensity <- min(students$propensity[students$tutored==1]))
students.subset <- students[students$propensity >= lowestpropensity,]
plot(students.subset$first_session_marks, students.subset$second_session_marks,
col = factor(students.subset$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ first_session_marks + tutored, data = students.subset)
summary(regression_model)
anova(regression_model)
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12, method = "pval"){
#Assign aptitude scores and generate first session marks
nstudents <- n_tutored + n_untutored
aptitude <- rnorm(nstudents, 0, 1)
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students <- students[order(students$first_session),]
#Randomly assign tutoring to 50% of students in the bottom n_tutored*2 of first session marks.
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
#Generate second session marks from aptitude, with a bump in marks for those who were tutored
students$second_session <- rnorm(nstudents, beta0 + beta1*students$aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
#Subset to include only students in the range where tutoring was offered
maxtutoredmark <- max(students$first_session_marks[students$tutored==1])
students.subset <- students[students$first_session_marks <= maxtutoredmark]
#Fit  a linear regression to get the p-value on the tutoring effect estimate.
lmod <- summary(lm(second_session ~ first_session + tutored, data = students.subset))
if (method == "pval"){return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
#An option to return the coefficient value only if it is significant.
} else if (method == "coeff" & lmod$coefficients[3,4] < 0.05){return(lmod$coefficients[3,1])
} else if (method == "coeff" & lmod$coefficients[3,4] >= 0.05){return(NA)}
}
pvals <- replicate(10000, power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 1,
sigma_secondsession = 2))
power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 1,
sigma_secondsession = 2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
students <- data.frame(aptitude)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for some values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
propmod <- glm(tutored ~ first_session_marks, family = "binomial", data = students)
summary(propmod)
students$propensity <- predict(propmod, newdata = students, type = "response")
(lowestpropensity <- min(students$propensity[students$tutored==1]))
students.subset <- students[students$propensity >= lowestpropensity,]
plot(students.subset$first_session_marks, students.subset$second_session_marks,
col = factor(students.subset$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ first_session_marks + tutored, data = students.subset)
summary(regression_model)
anova(regression_model)
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12, method = "pval"){
#Assign aptitude scores and generate first session marks
nstudents <- n_tutored + n_untutored
aptitude <- rnorm(nstudents, 0, 1)
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students <- students[order(students$first_session),]
#Randomly assign tutoring to 50% of students in the bottom n_tutored*2 of first session marks.
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
#Generate second session marks from aptitude, with a bump in marks for those who were tutored
students$second_session <- rnorm(nstudents, beta0 + beta1*students$aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
#Subset to include only students in the range where tutoring was offered
maxtutoredmark <- max(students$first_session[students$tutored==1])
students.subset <- students[students$first_session <= maxtutoredmark]
#Fit  a linear regression to get the p-value on the tutoring effect estimate.
lmod <- summary(lm(second_session ~ first_session + tutored, data = students.subset))
if (method == "pval"){return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
#An option to return the coefficient value only if it is significant.
} else if (method == "coeff" & lmod$coefficients[3,4] < 0.05){return(lmod$coefficients[3,1])
} else if (method == "coeff" & lmod$coefficients[3,4] >= 0.05){return(NA)}
}
pvals <- replicate(10000, power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 1,
sigma_secondsession = 2))
power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 1,
sigma_secondsession = 2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
n_students <- 500
n_tutoring <- 50
meanmark <- 60.0
marks_sd <- 12.0
aptitude <- rnorm(n_students, 0.0, 1.0)
students <- data.frame(aptitude)
luck <- 2
students$first_session_marks <- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)
#It is possible for some values to fall off the scale.
students$first_session_marks[students$first_session_marks > 100] <- 100
students$first_session_marks[students$first_session_marks < 0] <- 0
hist(students$first_session_marks, breaks = 15)
students <- students[order(students$first_session_marks),]
n_tutoring_places_accepted <- 0
tutored <- rep(0, n_students)
i <- 1
while (n_tutoring_places_accepted < n_tutoring & i < n_students) {
rval <- runif(1)
if (rval < 0.8 - students$first_session_marks[i]/100){
tutored[[i]] <- 1
n_tutoring_places_accepted <- n_tutoring_places_accepted + 1
}
i <- i + 1
}
students$tutored <- tutored
sum(tutored)
beta_0 <- 58 #This is the mean mark in second session for untutored students
beta_1 <- 0.9
beta_2 <- 3
sigma <- 2 #Luck in second session.
students$second_session_marks.mu <- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks <- rnorm(n_students, students$second_session_marks.mu, sigma)
#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks > 100] <- 100
students$second_session_marks[students$second_session_marks < 0] <- 0
hist(students$second_session_marks, breaks = 15)
plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))
propmod <- glm(tutored ~ first_session_marks, family = "binomial", data = students)
summary(propmod)
students$propensity <- predict(propmod, newdata = students, type = "response")
(lowestpropensity <- min(students$propensity[students$tutored==1]))
students.subset <- students[students$propensity >= lowestpropensity,]
plot(students.subset$first_session_marks, students.subset$second_session_marks,
col = factor(students.subset$tutored, levels = c(0,1)))
regression_model <- lm(second_session_marks ~ first_session_marks + tutored, data = students.subset)
summary(regression_model)
anova(regression_model)
power_simulation <- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12, method = "pval"){
#Assign aptitude scores and generate first session marks
nstudents <- n_tutored + n_untutored
aptitude <- rnorm(nstudents, 0, 1)
students <- data.frame(aptitude)
students$first_session <- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
students <- students[order(students$first_session),]
#Randomly assign tutoring to 50% of students in the bottom n_tutored*2 of first session marks.
tutored.indices <- sample(seq(1,n_tutored*2), n_tutored)
tutored <- rep(0, nstudents)
tutored[tutored.indices] <- 1
students$tutored <- tutored
#Generate second session marks from aptitude, with a bump in marks for those who were tutored
students$second_session <- rnorm(nstudents, beta0 + beta1*students$aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
#Subset to include only students in the range where tutoring was offered
maxtutoredmark <- max(students$first_session[students$tutored==1])
students.subset <- students[students$first_session <= maxtutoredmark,]
#Fit  a linear regression to get the p-value on the tutoring effect estimate.
lmod <- summary(lm(second_session ~ first_session + tutored, data = students.subset))
if (method == "pval"){return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
#An option to return the coefficient value only if it is significant.
} else if (method == "coeff" & lmod$coefficients[3,4] < 0.05){return(lmod$coefficients[3,1])
} else if (method == "coeff" & lmod$coefficients[3,4] >= 0.05){return(NA)}
}
pvals <- replicate(10000, power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 1,
sigma_secondsession = 2))
mean(pvals < 0.05)
tutoring_effects <- replicate(10000, power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 1,
sigma_secondsession = 2,
method = "coeff"))
hist(tutoring_effects)
small_noisy_tutoring_effects <- replicate(10000, power_simulation(n_tutored = 50,
n_untutored = 450,
tutoring_effect = 0.1,
sigma_secondsession = 6,
method = "coeff"))
hist(small_noisy_tutoring_effects, breaks = 50)
library(blogdown)
serve_site()
setwd("~/blog3/content/post")
serve_site()
