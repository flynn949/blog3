<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.48" />
  <meta name="author" content="Flynn Hill">

  
  
  
  
    
  
  <meta name="description" content="I recently attended a whole-day workshop on multilevel modelling organised by NIASRA and taught by Professor Mark Tranmer, who is an expert in the field from the University of Glasgow.
One part of the workshop that I realised I didn’t have any familiarity with was the idea of how variance works in logistic regression, and in particular in a multilevel logistic regression.
Here is one way of looking at logistic regression, in a formulation that reflects how a glm works:">

  
  <link rel="alternate" hreflang="en-us" href="/post/multilevel-logistic-regression/">

  


  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Flynn R Hill">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Flynn R Hill">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/multilevel-logistic-regression/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Flynn R Hill">
  <meta property="og:url" content="/post/multilevel-logistic-regression/">
  <meta property="og:title" content="Multilevel logistic regression (again) | Flynn R Hill">
  <meta property="og:description" content="I recently attended a whole-day workshop on multilevel modelling organised by NIASRA and taught by Professor Mark Tranmer, who is an expert in the field from the University of Glasgow.
One part of the workshop that I realised I didn’t have any familiarity with was the idea of how variance works in logistic regression, and in particular in a multilevel logistic regression.
Here is one way of looking at logistic regression, in a formulation that reflects how a glm works:">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-11-26T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-11-26T00:00:00&#43;00:00">
  

  

  

  <title>Multilevel logistic regression (again) | Flynn R Hill</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Flynn R Hill</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Multilevel logistic regression (again)</h1>

    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Flynn Hill">
  </span>
  

  <span class="article-date">
    
    <meta content="2018-11-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2018-11-26 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      2018-11-26
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Flynn Hill">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/multilevel-logistic-regression/#disqus_thread"></a>
  

  
  
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Multilevel%20logistic%20regression%20%28again%29&amp;url=%2fpost%2fmultilevel-logistic-regression%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fmultilevel-logistic-regression%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fmultilevel-logistic-regression%2f&amp;title=Multilevel%20logistic%20regression%20%28again%29"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fmultilevel-logistic-regression%2f&amp;title=Multilevel%20logistic%20regression%20%28again%29"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Multilevel%20logistic%20regression%20%28again%29&amp;body=%2fpost%2fmultilevel-logistic-regression%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      <p>I recently attended a whole-day workshop on multilevel modelling organised by <a href="https://niasra.uow.edu.au/index.html">NIASRA</a> and taught by Professor <a href="https://www.gla.ac.uk/schools/socialpolitical/staff/marktranmer/">Mark Tranmer</a>, who is an expert in the field from the University of Glasgow.</p>
<p>One part of the workshop that I realised I didn’t have any familiarity with was the idea of how variance works in logistic regression, and in particular in a multilevel logistic regression.</p>
<p>Here is one way of looking at logistic regression, in a formulation that reflects how a glm works:</p>
<p><span class="math display">\[ y_{prob} = \text{logit}^{-1}(X\beta) \\ y_{obs} \sim \text{Binomial}(y_{prob}) \]</span></p>
<p>Where <span class="math inline">\(\text{logit}^{-1}\)</span> is the inverse logit function: <span class="math inline">\(exp(X\beta)/(exp(X\beta) + 1)\)</span> which transforms the linear predictor <span class="math inline">\(X\beta\)</span> from log-odds to probabilities <span class="math inline">\(y_{prob}\)</span>. These then give the observed outcomes <span class="math inline">\(y_{obs}\)</span> according to a binomial distribution.</p>
<p>In multilevel logistic regression, it turns out that adding group (random) effects increases the residual variance. This presents a challenge when we are trying to decide whether it is worth including a group effect. What can we say about how much of the total variance is explained by the group effect?</p>
<p>To explore this issue, the latent variable model is helpful. Although mathematically equivalent to the glm formulation above, this conceptualisation offers an easier way to look at the variance.</p>
<p>In the latent variable model, there is an underlying linear variable <span class="math inline">\(y^*\)</span>, which produces a <span class="math inline">\(y_{obs}\)</span> value of 1 when it is above 0 and 0 when it is below 0. <span class="math inline">\(y^*\)</span> is given by a predictor with standard logistic distribution, centred at a value given by a linear predictor, with a scale of 1. This distribution has a variance of (pi^2)/3 = 3.29.</p>
<p><span class="math display">\[ y_{prob}=X\beta \\ y^* \sim \text{logistic}(y_{prob}, 1) \\ y_{obs}=y^*\geq0\;?\; 1 : 0 \]</span></p>
<p>The logistic distribution has a cumulative distribution function given by</p>
<p><span class="math display">\[ \frac{1}{2} + \frac{1}{2}\text{tanh}(\frac{x-\mu}{2s})\]</span></p>
<p>The CDF of a logistic distribution (black) with scale parameter <span class="math inline">\(s=1\)</span> is almost identical to a normal distribution with a variance of 3.29 (red).</p>
<pre class="r"><code>x &lt;- seq(-10,10,0.01)
pl &lt;- plogis(x, location = 0, scale = 1)
nl&lt;- pnorm(x, mean = 0, sd = sqrt(pi*pi/3))
plot(x,pl,t=&quot;l&quot;)
lines(x, nl, col=&quot;red&quot;)</code></pre>
<p><img src="/post/2018-11-26-multilevel-logistic-regression_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>How does this apply to multilevel models? We can put all population effects into <span class="math inline">\(y_{prob}\)</span> and calculate <span class="math inline">\(y^*\)</span> from a logistic distribution centred on <span class="math inline">\(y_{prob}\)</span>, plus an additional intercept term <span class="math inline">\(u_j\)</span> for the group effect, which stretches out <span class="math inline">\(y^*\)</span>:</p>
<p><span class="math display">\[ y_{prob}=X\beta \\ y^* \sim \text{logistic}(y_{prob}, 1)+u_j \\ y_{obs}=y^*\geq0\;?\; 1 : 0 \]</span></p>
<p>Thus, the population effects are set to contribute a variance of 3.29, while any group effects are added on top of this variance. If we subtract 3.29 from the total residual variance, we can find the variance attributable to the group effect, and take this as a proportion of the total variance.</p>
<div id="simulation" class="section level2">
<h2>Simulation</h2>
<pre class="r"><code>set.seed(1)</code></pre>
<p>Here, I simulate a dataset by way of the latent variable formulation above. This allows us to know the true proportion of variance explained by the group effect.</p>
<p>Setup:</p>
<ul>
<li>Binary outcome yobs</li>
<li>One continuous predictor x1</li>
<li>One binary predictor x2</li>
<li>A group level effect with varying intercepts uj.</li>
</ul>
<p>To make it interesting, the distribution of the binary predictor x2 will vary by group, with some groups having many more observations with x2=1 and some having very few.</p>
<pre class="r"><code>multibin &lt;- function(n, J, beta1, beta2, jstd){
  group &lt;- sample(J, n, replace=TRUE) #group membership indicator
  x1 &lt;- rnorm(n,0,1) #standard continuous predictor variable
  x2 &lt;- rep(NA,length(group))
  group_probs &lt;- runif(20) #probability of x2=1 for members of each group
  for (i in 1:length(group)){
    x2[i] &lt;- sample(c(0,1), prob = c(1 - group_probs[group[i]], group_probs[group[i]]))
  }
  uj &lt;- rnorm(J,0,jstd) #Group intercepts, normally distributed with standard deviation jstd
  yprob &lt;- rep(NA,n)
  for (i in 1:n){
    yprob[i] &lt;- x1[i]*beta1 + x2[i]*beta2 #calculate yprob including only the population (fixed) effects.
  }
  ystar &lt;- rlogis(n,yprob,1) # var(ystar - yprob) = 3.29
  for (i in 1:n){
    ystar[i] &lt;- ystar[i] + uj[group[i]] #Add the group effect to ystar
  }
  yobs &lt;- ifelse(ystar &gt;= 0, 1, 0) #Get the binary outcome using the threshold test
  return(data.frame(x1, x2, group, yprob, ystar, yobs))
}</code></pre>
<p>Now a dataset is generated, note the value of 1.5 for jstd, the standard deviation of the group intercepts. This corresponds to a variance of 2.25.</p>
<pre class="r"><code>mdata &lt;- multibin(n = 5000, 
                  J = 20, 
                  beta1 = 1.6, #3.2
                  beta2 = -0.7,
                  jstd = 1.5)</code></pre>
<pre class="r"><code>head(mdata)</code></pre>
<pre><code>##           x1 x2 group      yprob      ystar yobs
## 1 -1.8054836  0     6 -2.8887737 -4.0269975    0
## 2 -0.6780407  0     8 -1.0848651  1.4070274    1
## 3 -0.4733581  1    12 -1.4573729 -3.2942698    0
## 4  1.0274171  0    19  1.6438673 -0.8470214    0
## 5 -0.5973876  0     5 -0.9558201 -2.5958663    0
## 6  1.1598494  1    18  1.1557590  2.8085406    1</code></pre>
<p>Now let’s plot the data, for a small subset of the groups (and a subsample within each group). Keep in mind that in a real study, ystar, being a latent variable, is invisible.</p>
<pre class="r"><code>mdata %&gt;%
  filter(group %in% seq(1,4)) %&gt;%
  mutate(Group = paste0(&quot;Group &quot;, group)) %&gt;%
  group_by(Group) %&gt;%
  sample_n(100) %&gt;%
  ggplot()+
  aes(x = x1, y = ystar, col = factor(Group), shape = factor(x2))+
  geom_hline(yintercept = 0, col = &quot;grey&quot;, linetype = &quot;dashed&quot;)+
  geom_point(alpha = 0.3)+
  geom_point(aes(x = x1, y = yobs), size = 1.5)+
  scale_colour_discrete(guide = FALSE)+
  scale_shape_discrete(name = &quot;x2&quot;)+
  theme_bw(14)+
  facet_wrap(~Group)</code></pre>
<p><img src="/post/2018-11-26-multilevel-logistic-regression_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The variance of the residuals should be approximately 3.29 + some variance attributable to the group-level effect. We can calculate the true variance from our simulation.</p>
<p><span class="math display">\[\sigma^{2}_{\text{total}}=\text{var}(y^*-y_{prob})\]</span></p>
<pre class="r"><code>var(mdata$ystar - mdata$yprob)</code></pre>
<pre><code>## [1] 6.064065</code></pre>
<p>How much variance did the group level effect add?</p>
<p><span class="math display">\[\sigma^{2}_{\text{total}} = \sigma^{2}_{e*} + \sigma^{2}_{u}\]</span></p>
<p>Where <span class="math inline">\(\sigma^{2}_{e*}\)</span> is the variance attributable to the population (fixed) effects and <span class="math inline">\(\sigma^{2}_{u}\)</span> is the variance attributable to the group (random) effects.</p>
<pre class="r"><code>var(mdata$ystar - mdata$yprob) - (pi*pi)/3</code></pre>
<pre><code>## [1] 2.774197</code></pre>
<p>What proportion of the total variance does this represent? I.e. what is the variance partition coefficient (VPC)?</p>
<p><span class="math display">\[ VPC = \frac{\sigma^{2}_{u}}{\sigma^{2}_{e*}+\sigma^{2}_{u}}\]</span></p>
<pre class="r"><code>(var(mdata$ystar - mdata$yprob) - (pi*pi)/3)/var(mdata$ystar - mdata$yprob)</code></pre>
<pre><code>## [1] 0.4574814</code></pre>
<p>About 46%.</p>
<p>Now that we know the true variance values to expect from the simulation, we can fit a multilevel logistic regression model and see how close it gets. Here, I use the function glmer from the package lme4, which uses a maximum likelihood estimator. One point Prof Tranmer made in his talk was that Bayesian Markov Chain Monte Carlo estimators may do a better job for this particular problem, however, I have simulated a lot of observations so it shouldn’t really make a difference. If I wanted to use MCMC, the package brms can accept a formula in the same syntax as lme4.</p>
<pre class="r"><code>mmod1 &lt;- glmer(yobs ~ x1 + x2 + (1 | group), 
              data = mdata, 
              family = &quot;binomial&quot;)

summary(mmod1)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: yobs ~ x1 + x2 + (1 | group)
##    Data: mdata
## 
##      AIC      BIC   logLik deviance df.resid 
##   4264.3   4290.4  -2128.2   4256.3     4996 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -6.5275 -0.4905 -0.1512  0.4567 13.0062 
## 
## Random effects:
##  Groups Name        Variance Std.Dev.
##  group  (Intercept) 2.685    1.638   
## Number of obs: 5000, groups:  group, 20
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.14883    0.37175  -0.400    0.689    
## x1           1.60081    0.05353  29.905  &lt; 2e-16 ***
## x2          -0.75155    0.09457  -7.947 1.91e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##    (Intr) x1    
## x1 -0.008       
## x2 -0.129 -0.120</code></pre>
<p>Looking at the summary, the variance attributable to the group (random effect) is pretty close to the true value. If this were a real model, the VPC of 46% would mean we would be certain to include the group effect. Now we can plot the varying interecepts model for <span class="math inline">\(y^*\)</span> (for the same subset of data as above). Each group has two lines, one for each value of the predictor x2.</p>
<pre class="r"><code>mdata$predicted &lt;- predict(mmod1, mdata)</code></pre>
<pre class="r"><code>mdata %&gt;%
  filter(group %in% seq(1,4)) %&gt;%
  mutate(Group = paste0(&quot;Group &quot;, group)) %&gt;%
  group_by(Group) %&gt;%
  sample_n(100) %&gt;%
  ggplot()+
  aes(x = x1, y = ystar, col = factor(Group), shape = factor(x2))+
  geom_hline(yintercept = 0, col = &quot;grey&quot;, linetype = &quot;dashed&quot;)+
  geom_point(alpha = 0.3)+
  geom_point(aes(x = x1, y = yobs), size = 1.5)+
  geom_line(aes(x = x1, y = predicted, group = interaction(x2,group)))+
  scale_colour_discrete(guide = FALSE)+
  scale_shape_discrete(name = &quot;x2&quot;)+
  scale_x_continuous(limits = c(-2,2))+
  theme_bw(14)+
  facet_wrap(~Group)</code></pre>
<p><img src="/post/2018-11-26-multilevel-logistic-regression_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<p>Goldstein H, Browne W, Rasbash J. Partitioning variation in generalised linear multilevel models. Understanding Statistics 2002; 1:223–232</p>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/multilevel-modelling/">multilevel modelling</a>
  
  <a class="badge badge-light" href="/tags/logistic-regression/">logistic regression</a>
  
  <a class="badge badge-light" href="/tags/variance/">variance</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/hierarchical-logistic-regression/">Hierarchical Logistic Regression</a></li>
        
      </ul>
    </div>
    

    

    <div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://frhill.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/tex.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/c&#43;&#43;.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//frhill.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    
    

    
    

    

  </body>
</html>

