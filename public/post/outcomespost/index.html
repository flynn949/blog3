<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.48" />
  <meta name="author" content="Flynn Hill">

  
  
  
  
    
  
  <meta name="description" content="In this post, I will run through a simple experiment simulation using only base R, and demonstrate a way to do power analysis by using this simulation. Say we have a cohort of 500 first-year students commencing their second session of study. We decide to offer a special tutoring service to some of the students who did not go well in their first session. To do this, we arrange students in ascending order of their averaged first session final marks, and go down the list calling students and offering tutoring services until 50 students have taken up the offer.">

  
  <link rel="alternate" hreflang="en-us" href="/post/outcomespost/">

  


  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Flynn R Hill">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Flynn R Hill">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/outcomespost/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Flynn R Hill">
  <meta property="og:url" content="/post/outcomespost/">
  <meta property="og:title" content="Quantifying an educational effect | Flynn R Hill">
  <meta property="og:description" content="In this post, I will run through a simple experiment simulation using only base R, and demonstrate a way to do power analysis by using this simulation. Say we have a cohort of 500 first-year students commencing their second session of study. We decide to offer a special tutoring service to some of the students who did not go well in their first session. To do this, we arrange students in ascending order of their averaged first session final marks, and go down the list calling students and offering tutoring services until 50 students have taken up the offer.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-09-13T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-09-13T00:00:00&#43;00:00">
  

  

  

  <title>Quantifying an educational effect | Flynn R Hill</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Flynn R Hill</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Quantifying an educational effect</h1>

    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Flynn Hill">
  </span>
  

  <span class="article-date">
    
    <meta content="2018-09-13 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2018-09-13 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      2018-09-13
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Flynn Hill">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    9 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/outcomespost/#disqus_thread"></a>
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Quantifying%20an%20educational%20effect&amp;url=%2fpost%2foutcomespost%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2foutcomespost%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2foutcomespost%2f&amp;title=Quantifying%20an%20educational%20effect"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2foutcomespost%2f&amp;title=Quantifying%20an%20educational%20effect"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Quantifying%20an%20educational%20effect&amp;body=%2fpost%2foutcomespost%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      <p>In this post, I will run through a simple experiment simulation using only base R, and demonstrate a way to do power analysis by using this simulation. Say we have a cohort of 500 first-year students commencing their second session of study. We decide to offer a special tutoring service to some of the students who did not go well in their first session. To do this, we arrange students in ascending order of their averaged first session final marks, and go down the list calling students and offering tutoring services until 50 students have taken up the offer. At the end of the second session, we want to see if this made a difference. Here we will consider a simple situation where all relevant variables have been taken into account, and the effect is therefore consistent for all students - if only real life were so simple!</p>
<p>Although I am usually a devotee of the tidyverse, to keep things simple and focus on the procedure, I have used only base R in this post.</p>
<div id="simulation" class="section level3">
<h3>Simulation</h3>
<p>Start with the basic parameters.</p>
<pre class="r"><code>set.seed(42)
n_students &lt;- 500
n_tutoring &lt;- 50</code></pre>
<p>Start with a latent parameter - let’s call it aptitude - which for simplicity’s sake will be the only thing (besides a bit of luck) that determines students’ marks. As a latent variable, the most appropriate scale for this would be a standard normal, but for convenience we will also put it on the same scale as marks.</p>
<pre class="r"><code>meanmark &lt;- 60.0
marks_sd &lt;- 12.0


aptitude &lt;- rnorm(n_students, 0.0, 1.0)
students &lt;- data.frame(aptitude)</code></pre>
<p>Generate a reasonable looking distribution of first-session marks, based on students’ aptitude, plus or minus a little bit of luck.</p>
<pre class="r"><code>luck &lt;- 2

students$first_session_marks &lt;- rnorm(n_students, students$aptitude*marks_sd + meanmark, luck)

#It is possible for some values to fall off the scale.
students$first_session_marks[students$first_session_marks &gt; 100] &lt;- 100
students$first_session_marks[students$first_session_marks &lt; 0] &lt;- 0


hist(students$first_session_marks, breaks = 15)</code></pre>
<p><img src="/post/outcomespost_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Now we start calling students to offer them tutoring, starting from those with the lowest first session marks. Here, the probability of a student accepting tutoring is 0.8 - first_session_mark/100, i.e. students with lower marks are more likely to accept tutoring.</p>
<pre class="r"><code>students &lt;- students[order(students$first_session_marks),]

n_tutoring_places_accepted &lt;- 0
tutored &lt;- rep(0, n_students)
i &lt;- 1
while (n_tutoring_places_accepted &lt; n_tutoring &amp; i &lt; n_students) {
 rval &lt;- runif(1) 
 if (rval &lt; 0.8 - students$first_session_marks[i]/100){
   tutored[[i]] &lt;- 1
   n_tutoring_places_accepted &lt;- n_tutoring_places_accepted + 1
 }
 i &lt;- i + 1
}

students$tutored &lt;- tutored

sum(tutored)</code></pre>
<pre><code>## [1] 50</code></pre>
<p>Now simulate second session marks. These will also be based on students’ underlying aptitude, and will be similar to the first session marks, but because the courses have changed there may be a different overall mean and scaling of marks with respect to to aptitude. To keep things simple (and unrealistic), students’ underlying aptitude has not changed. In this model, there is an intercept term that gives the average (untutored) mark, a slope term that scales the mark with respect to aptitude, and another interept term for the effect associated with tutoring. Realised values of the second session mark are then drawn from Gaussian distributions centred at these calculated mark values, with a defined standard deviation that is the same for all students. Thus, for student <span class="math inline">\(i\)</span> we have:</p>
<p><span class="math display">\[\text{Second session mark}_i \sim \text{Normal}(\mu_i,\sigma)\\ \mu_i = \beta_0 + \beta_1\text{aptitude}_i + \beta_2\text{Tutored}_i \]</span> Define the parameters, and generate the second session marks according to the model. Here, we have very ambitiously assumed that tutoring increases students marks (to say nothing of whether it changes their aptitude) by 3 points.</p>
<pre class="r"><code>beta_0 &lt;- 58 #This is the mean mark in second session for untutored students
beta_1 &lt;- 0.9
beta_2 &lt;- 3
sigma &lt;- 2 #Luck in second session.

students$second_session_marks.mu &lt;- beta_0 + beta_1*students$aptitude*marks_sd + beta_2*students$tutored
students$second_session_marks &lt;- rnorm(n_students, students$second_session_marks.mu, sigma)

#Once again, it is possible that some values could have fallen off the scale, and this is one simple way to fix that:
students$second_session_marks[students$second_session_marks &gt; 100] &lt;- 100
students$second_session_marks[students$second_session_marks &lt; 0] &lt;- 0


hist(students$second_session_marks, breaks = 15)</code></pre>
<p><img src="/post/outcomespost_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Plot the first and second session marks, coloured by whether tutoring was accepted.</p>
<pre class="r"><code>plot(students$first_session_marks, students$second_session_marks, col = factor(students$tutored, levels = c(0,1)))</code></pre>
<p><img src="/post/outcomespost_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Students who received tutoring have had a small but appreciable bump in their marks. To measure the bump in marks, fit a linear regression, with a term for the tutoring effect. Students who were tutored have a value of 1 for the variable ‘tutored’, while those who weren’t tutored have a value of 0, so any coefficient on this variable is essentially an intercept term.</p>
<pre class="r"><code>regression_model &lt;- lm(second_session_marks ~ first_session_marks + tutored, data = students)
summary(regression_model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = second_session_marks ~ first_session_marks + tutored, 
##     data = students)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.6009 -1.8214 -0.0217  1.9152  6.8597 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          5.12799    0.70304   7.294 1.20e-12 ***
## first_session_marks  0.88062    0.01129  77.996  &lt; 2e-16 ***
## tutored              3.19887    0.44480   7.192 2.37e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.717 on 497 degrees of freedom
## Multiple R-squared:  0.9323, Adjusted R-squared:  0.932 
## F-statistic:  3421 on 2 and 497 DF,  p-value: &lt; 2.2e-16</code></pre>
<p> </p>
<p>Note that we are now regressing against first session marks as a measure of the underlying aptitude from which the marks were drawn. Nonetheless, the model has retrieved fairly reasonable estimates for the coefficients - no surprise, they are a less noisy than real data, all relevant variables have been included, and the effect size is appreciable and consistent.</p>
<p>An interesting point to note here is that some of the students who were offered tutoring may have received that offer because they were unlucky in first session and got marks a bit lower than what would be expected for their aptitude. In the second session, these students could be expected to get better marks regardless of being tutored - this is called <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean">regression to the mean</a>, and could be very problematic for a study such as this one.</p>
<p> </p>
</div>
<div id="power-analysis-by-simulation" class="section level3">
<h3>Power analysis by simulation</h3>
<p>A good idea before doing a study like this is to calculate its power - the probability of rejecting the null hypothesis when the null hypothesis is false (at a given significance level). This calculation can either help us to decide how many study subjects are needed to reach a desired power level, or if we are unable to increase the number of study subjects it can at least give us a realistic appreciation for the power of our study. There is a nice illustration of the concept of power in <a href="http://rpsychologist.com/d3/NHST/">this post</a> by Kristoffer Magnusson.</p>
<p>We can use this simulation to find the power for an estimated effect size, or to find the minimum effect size needed to achieve a given power. By replicating the above simulation thousands of times, we can quantify the fraction for which the p-value of the tutoring effect coefficient was below the significance level. It is important to note that the effect size here is measured in units of marks, whereas effect sizes are often put into standard units by dividing by the standard deviation. The power simulation uses a simpler model to decide which students receive tutoring - for the bottom 100 students, each has a 50% chance of accepting tutoring (up to a maximum of 50 tutoring places). This mimics a situation in which we have no model for who is more likely to accept tutoring. The results of this power analysis could therefore mislead us.</p>
<pre class="r"><code>power_simulation &lt;- function(n_tutored = 50, n_untutored = 450, tutoring_effect, sigma_secondsession, beta0 = 58, beta1 = 0.9, marks_sd = 12, method = &quot;pval&quot;){
  #Assign aptitude scores and generate first session marks
  nstudents &lt;- n_tutored + n_untutored 
  aptitude &lt;- rnorm(nstudents, 0, 1)
  students &lt;- data.frame(aptitude)
  students$first_session &lt;- rnorm(nstudents, students$aptitude*marks_sd + 60, 2)
  students &lt;- students[order(students$first_session),]
  #Randomly assign tutoring to 50% of students in the bottom n_tutored*2 of first session marks.
  tutored.indices &lt;- sample(seq(1,n_tutored*2), n_tutored)
  tutored &lt;- rep(0, nstudents)
  tutored[tutored.indices] &lt;- 1
  students$tutored &lt;- tutored
  #Generate second session marks from aptitude, with a bump in marks for those who were tutored
  students$second_session &lt;- rnorm(nstudents, beta0 + beta1*students$aptitude*marks_sd + tutoring_effect*students$tutored, sigma_secondsession)
  #Fit  a linear regression to get the p-value on the tutoring effect estimate.
  lmod &lt;- summary(lm(second_session ~ first_session + tutored, data = students))
  if (method == &quot;pval&quot;){return(lmod$coefficients[3,4]) #The pvalue for the tutoring_effect estimate.
    #An option to return the coefficient value only if it is significant.
  } else if (method == &quot;coeff&quot; &amp; lmod$coefficients[3,4] &lt; 0.05){return(lmod$coefficients[3,1])
  } else if (method == &quot;coeff&quot; &amp; lmod$coefficients[3,4] &gt;= 0.05){return(NA)}
}

pvals &lt;- replicate(10000, power_simulation(n_tutored = 50, 
                                           n_untutored = 450, 
                                           tutoring_effect = 1, 
                                           sigma_secondsession = 2))

mean(pvals &lt; 0.05)</code></pre>
<pre><code>## [1] 0.6001</code></pre>
<p>So, we have a calculated power of 0.6 when there is an effect of +1 mark. The histogram below shows values of the coefficent for all simulations in which the p-value was below 0.05. Surprisingly, the true value of 1 is at the lower end of the range here. Selecting for only the statistically significant values has selected for those with inflated estimates, and the regression to the mean problem mentioned earlier is probably also making a contribution. Estimates range between 1 and 2 marks. In a noisier simulation, or one with a smaller effect size, the tutoring estimate could possibly even come out as both negative <em>and</em> statistically significant.</p>
<pre class="r"><code>tutoring_effects &lt;- replicate(10000, power_simulation(n_tutored = 50, 
                                                      n_untutored = 450, 
                                                      tutoring_effect = 1, 
                                                      sigma_secondsession = 2, 
                                                      method = &quot;coeff&quot;))

hist(tutoring_effects)</code></pre>
<p><img src="/post/outcomespost_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p> </p>
</div>
<div id="concluding-remarks" class="section level3">
<h3>Concluding remarks</h3>
<p>Going into a power analysis it is common to have a personal bias to thinking our effect size will be greater than it really is, and that the data are less noisy than they really are. Without going too much into the whys and wherefores of power analysis and null hypothesis significance testing, <a href="http://www.stat.columbia.edu/~gelman/research/published/PPS551642_REV2.pdf">it is good practice</a> to use a conservative estimate of the effect size based on external information (e.g. prior studies). If we wanted to make a proper attempt at doing a power analysis for an experiment like the one described above, we would need to have reasonable estimates for the distributions of marks, and a measure of how well correlated these are for students from session-to-session, to figure out the relationship to the underlying aptitude. If we go a step further and take into account that individual students’ aptitudes can be on an upward or downard trajectory, it starts to get very complicated.</p>
<p> </p>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/regression/">regression</a>
  
  <a class="badge badge-light" href="/tags/statistics/">statistics</a>
  
  <a class="badge badge-light" href="/tags/power-analysis/">power analysis</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/post_1/">Simulation and Modelling in R and Stan</a></li>
        
      </ul>
    </div>
    

    

    <div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://frhill.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/tex.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/c&#43;&#43;.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//frhill.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    
    

    
    

    

  </body>
</html>

