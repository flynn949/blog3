<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.48" />
  <meta name="author" content="Flynn Hill">

  
  
  
  
    
  
  <meta name="description" content="In this post, I simulate an example experiment in which there is a non-linear relationship with underlying parameters that vary by group membership, before fitting the data using Bayesian regression in Stan. In this example, inspired by a real-world problem (with details changed to protect future Nobel prize winners, so try not to read too much into it), several mutant strains of a species of bacteria have been exposed to a range of concentrations of Chemical X.">

  
  <link rel="alternate" hreflang="en-us" href="/post/post_1/">

  


  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Flynn R Hill">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Flynn R Hill">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/post_1/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Flynn R Hill">
  <meta property="og:url" content="/post/post_1/">
  <meta property="og:title" content="Simulation and Modelling in R and Stan | Flynn R Hill">
  <meta property="og:description" content="In this post, I simulate an example experiment in which there is a non-linear relationship with underlying parameters that vary by group membership, before fitting the data using Bayesian regression in Stan. In this example, inspired by a real-world problem (with details changed to protect future Nobel prize winners, so try not to read too much into it), several mutant strains of a species of bacteria have been exposed to a range of concentrations of Chemical X.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2018-08-27T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2018-08-27T00:00:00&#43;00:00">
  

  

  

  <title>Simulation and Modelling in R and Stan | Flynn R Hill</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Flynn R Hill</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Simulation and Modelling in R and Stan</h1>

    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Flynn Hill">
  </span>
  

  <span class="article-date">
    
    <meta content="2018-08-27 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2018-08-27 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      2018-08-27
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Flynn Hill">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    18 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/post_1/#disqus_thread"></a>
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Simulation%20and%20Modelling%20in%20R%20and%20Stan&amp;url=%2fpost%2fpost_1%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fpost_1%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fpost_1%2f&amp;title=Simulation%20and%20Modelling%20in%20R%20and%20Stan"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fpost_1%2f&amp;title=Simulation%20and%20Modelling%20in%20R%20and%20Stan"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Simulation%20and%20Modelling%20in%20R%20and%20Stan&amp;body=%2fpost%2fpost_1%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      <script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<p>In this post, I simulate an example experiment in which there is a non-linear relationship with underlying parameters that vary by group membership, before fitting the data using Bayesian regression in Stan. In this example, inspired by a real-world problem (with details changed to protect future Nobel prize winners, so try not to read too much into it), several mutant strains of a species of bacteria have been exposed to a range of concentrations of Chemical X. Individual bacteria are exposed, and their response is to either turn green (success) or not. Intriguingly, if a lot of trials are measured of a range of concentrations for a single strain (mutant A, below), there is a bell curve-shaped rise and fall in successes as a function of concentration. Resources are insufficient to measure this many trials for each mutant, so 20 trials at each concentration for each mutant instead. However, some of these trials failed due to a technical glitch and the number of trials ranges from 10-20. Of particular interest is position of the centre of each strain’s Gaussian-shaped response curve.</p>
<p><img src="/post/Post_1_files/figure-html/unnamed-chunk-1-1.png" width="864" /></p>
<p>For this problem, I will take the approach of fitting a model to the data that is based on an understanding of how the data were generated. This will be done using Bayesian inference, which goes a step further than simply finding a single set of most likely parameters, by finding the probability distribution for a wide range of possibile underlying paramters. For this, I use the probabilistic programming language Stan.</p>
<div id="model" class="section level2">
<h2>Model</h2>
<p>For each mutant, at each concentration, there is a certain number of trials and a certain number of successes. If the experiment were to be repeated many times, would we expect to get the exact same data every time? Of course not, but the numbers should be similar. The number of successes that are observed in any given experiment is stochastically drawn from some distribution. Our first task in defining the model is to identify the most appropriate distribution. In this case, the distribution that makes the most sense is the binomial distribution, which has two parameters: the number of trials, and the probability of success in each trial.</p>
<p>For each mutant at each concentration: the observed number of successes <span class="math inline">\(Y\)</span> is drawn from a binomial distribution parameterised by the probability of success <span class="math inline">\(p\)</span> and number of trials. The ~ symbol denotes a stochastic relationship.</p>
<p><span class="math display">\[Y \sim \text{Binomial(trials}\text{, }  p) \]</span></p>
<p>In the second part of the model, the true success probability <span class="math inline">\(p\)</span> for mutant <span class="math inline">\(j\)</span> at concentration <span class="math inline">\(x_i\)</span> is given by a Gaussian curve parameterised by the peak height <span class="math inline">\(h_j\)</span> (in units of success probability), peak centre position <span class="math inline">\(c_j\)</span> (in units of concentration), and its width (standard deviation) <span class="math inline">\(\sigma\)</span> (in units of concentration).</p>
<p><span class="math display">\[p_{j,i} = h_j \text{ exp}{\frac{-(x_i-c_j)^2}{2\sigma_j^2}}\]</span></p>
<div id="bayes-rule" class="section level3">
<h3>Bayes’ Rule</h3>
<p>For a given set of parameters, a range of observations can be obtained stochastically from the binomial distribution. The corollary of this is that for a given set of observations, a range of underlying parameters could have created them. The above model can be used to calculate the likelihood of the observed data for any of a range of candidate parameter values. From this, the probability of any particular set of parameters having created the data can also be assessed. This is achieved using Bayes’ rule, given here in the un-normalised form:</p>
<p><span class="math display">\[P(\text{Parameters | Data}) \propto P(\text{Data | Parameters}).P(\text{Parameters}) \]</span> Where:</p>
<ul>
<li><span class="math inline">\(P(\text{Parameters | Data})\)</span> is the posterior probability - the probability of a given set of candidate parameters conditional on the observed data.</li>
<li><span class="math inline">\(P(\text{Data | Parameters})\)</span> is the likelihood. The above model is critical in calculating this - for a given set of parameters, how likely are the observed data to have been stochastically drawn from the distribution these parameters imply?</li>
<li><span class="math inline">\(P(\text{Parameters})\)</span> is the prior probability of the candidate parameters. This may have support from previous experiments, or it may have to represent an educated guess.</li>
</ul>
<p>In the normalised form, the terms on the right are divided by the marginal likelihood of observing the data, integrated over all possible parameters, to make the terms on the right equal to the posterior probability on the left. In general, this is more difficult to achieve, and if our only aim is to assess the probability of one set of paramters relative to another, it is not necessary.</p>
</div>
<div id="sampling" class="section level3">
<h3>Sampling</h3>
<p>How can Bayes’ rule be applied to the above problem? For relatively simple problems, Bayes’ rule can be applied analytically, and an exact solution for the posterior probability distribution can be found. For more complicated problems like this one, a sampling approach is the only viable option. These methods build up a picture of what the posterior probability distribution looks like, one set of candidate parameters at a time. The challenge in sampling is to efficiently explore the posterior probability distribution.</p>
<p>There are several Markov Chain Monte Carlo (MCMC) sampling algorithms, including Gibbs sampling and Hamiltonian Monte Carlo, but the basic principles of these are pretty much as follows:</p>
<p>Setup</p>
<ul>
<li>A prior probability distribution is specified for each parameter.</li>
<li>A formula for the likelihood is specified.</li>
<li>A random (or specified) set of parameters are taken as the initial candidate parameters</li>
<li>The number of sampling iterations is defined. Depending on the problem, the first several hundred or thousand of these will be discarded, as they have started at some random part of parameter space and have not yet equilibrated to the posterior distribution.</li>
</ul>
<p>Sampling</p>
<ol style="list-style-type: decimal">
<li>The likelihood of obtaining the observed data given the candidate parameters is calculated and multiplied by the prior probability. This gives the value on the right hand side of Bayes’ (un-normalised) formula.</li>
<li>The candidate set of parameters are either accepted or rejected, in some manner that is dependent on their probability. For example, by taking it as a ratio over the last accepted probability, and then stochastically choosing to accept or reject based on the value of this ratio.</li>
<li>A new set of candidate parameters is generated by treating the last accepted set of parameters as a jumping off point. For example, a set of random numbers may be added to these.</li>
</ol>
<p>In this way, the sampler explores each part of parameter space in proportion to its probability, and ultimately should thoroughly explore the joint probability density of all the parameters. Note that probabilities are calculated as log probabilities - this way, they can be added rather than multiplied, which is computationally much more achievable.</p>
<p><a href="https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/">Here’s</a> a really great blog post by Thomas Wiecki that explains the whole process very nicely.</p>
</div>
</div>
<div id="simulation" class="section level2">
<h2>Simulation</h2>
<p>A great way to proceed is by simulating data based on this model, and then fitting it with the corresponding regression model. In this way, we gain a deeper appreciation for how the model works, and can much more readily spot flaws in our thinking.</p>
<pre class="r"><code># Give each mutant a name.
n_mutants &lt;- 6
mutants &lt;- LETTERS[1:n_mutants]  

# Population-level intercepts
pop_height_logodds &lt;- 0
pop_centre &lt;- 70
pop_width &lt;- 1.5  

#Population scaling parameters
group_scale_height_logodds &lt;- 1
group_scale_centre &lt;- 4
group_scale_width &lt;- 0.5</code></pre>
<p> </p>
<div id="random-parameter-draw" class="section level3">
<h3>Random parameter draw</h3>
<p>True height and centre parameters for each mutant are now drawn from Gaussian distributions with the population centres and group standard deviations as given above. A random seed is specified to make this reproducible. The height values are in log-odds units, and are transformed to probability using the invlogit function. We can now make a table of the key parameters for each mutant. Note that mutants E and F have the same centre, while mutants B, C and E have the same height value.</p>
<pre class="r"><code>#invlogit function for converting log odds to probability
invlogit &lt;- function(x){exp(x)/(1+exp(x))}

#set random seed for reproducibility
set.seed(100)

height_raw_logodds &lt;- rnorm(n = n_mutants, mean = 0, sd = 1)
centre_raw &lt;- rnorm(n = n_mutants, mean = 0, sd = 1)
width_raw &lt;- rnorm(n = n_mutants, mean = 0, sd = 1)

mutant_height_logodds &lt;- pop_height_logodds + group_scale_height_logodds * height_raw_logodds
mutant_centre &lt;- pop_centre + group_scale_centre * centre_raw
mutant_width &lt;- pop_width + group_scale_width * width_raw

# Transform these parameters from log-odds to probability
mutant_height_p &lt;- invlogit(mutant_height_logodds)


# Data summary
mutant.frame &lt;- data.frame(&quot;mutant&quot; = mutants, 
                           &quot;height_logodds&quot; = mutant_height_logodds,   
                           &quot;height_p&quot; = mutant_height_p,
                           &quot;centre&quot; = mutant_centre, 
                           &quot;width&quot; = mutant_width)

kable(mutant.frame, format = &quot;html&quot;, digits = 1)%&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;))</code></pre>
<table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
mutant
</th>
<th style="text-align:right;">
height_logodds
</th>
<th style="text-align:right;">
height_p
</th>
<th style="text-align:right;">
centre
</th>
<th style="text-align:right;">
width
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
-0.5
</td>
<td style="text-align:right;">
0.4
</td>
<td style="text-align:right;">
67.7
</td>
<td style="text-align:right;">
1.4
</td>
</tr>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:right;">
72.9
</td>
<td style="text-align:right;">
1.9
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:right;">
-0.1
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:right;">
66.7
</td>
<td style="text-align:right;">
1.6
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:right;">
0.9
</td>
<td style="text-align:right;">
0.7
</td>
<td style="text-align:right;">
68.6
</td>
<td style="text-align:right;">
1.5
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:right;">
0.1
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:right;">
70.4
</td>
<td style="text-align:right;">
1.3
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
0.3
</td>
<td style="text-align:right;">
0.6
</td>
<td style="text-align:right;">
70.4
</td>
<td style="text-align:right;">
1.8
</td>
</tr>
</tbody>
</table>
<p> </p>
</div>
<div id="predictor-variable-and-number-of-trials" class="section level3">
<h3>Predictor variable and number of trials</h3>
<pre class="r"><code># Predictor variable
conc_range &lt;- 10
conc_interval &lt;- 1
conc &lt;- seq(pop_centre-conc_range, pop_centre + conc_range, conc_interval)

# Maximum number of repeats/trials
max_trials = 10

#Probability of max trials
prob_trials = 0.95 #A high value to simulate a situation where there is an intended number of trials, but some have failed for technical reasons.</code></pre>
<p> </p>
</div>
<div id="probability-of-success" class="section level3">
<h3>Probability of success</h3>
<p>The Gaussian function is defined and a probability matrix describing the probability of success for each mutant at each tested concentration is calculated, given the parameters height, centre, and width for each mutant.</p>
<pre class="r"><code>gaussian &lt;- function(height,centre,width,x){
  return(height * exp(-0.5* ( ((x - centre)^2)/(width^2)) ))
}

probability.matrix &lt;- matrix(data = NA, 
                             nrow = length(conc), 
                             ncol = n_mutants, 
                             dimnames = list(conc, mutants))

for (j in 1:n_mutants){
  for (i in 1:length(conc)){
    probability.matrix[i,j] &lt;- gaussian(mutant_height_p[j], 
                                        mutant_centre[j], 
                                        mutant_width[j], 
                                        conc[i])
    
  }
}</code></pre>
</div>
<div id="experiment-simulation" class="section level3">
<h3>Experiment simulation</h3>
<p>For each mutant, at each concentration, the number of trials can vary. Here this is achieved by drawing the number of trials from a binomial distribution (to simulate random technical failures), but that is not crucial to the model.</p>
<p>An experiment is now simulated by drawing from a binomial distribution for each mutant-concentration combination, parameterised the corresponding values from the probabilities matrix and number of trials matrix.</p>
<pre class="r"><code>n_trials.matrix &lt;- matrix(data = rbinom(n = length(conc)*n_mutants, 
                                        size = max_trials, 
                                        prob = prob_trials),  
                          nrow = length(conc), 
                          ncol = n_mutants, 
                          dimnames = list(conc, mutants))

# Simulate experiments - get the number of successes given the probability from the above matrix and the number of trials.
successes.matrix &lt;- matrix(data = NA, 
                           nrow = length(conc), 
                           ncol = n_mutants, 
                           dimnames = list(conc, mutants))

for (j in 1:n_mutants){
  for (i in 1:length(conc)){
    successes.matrix[i,j] &lt;- rbinom(1, 
                                    prob =  probability.matrix[i,j], 
                                    size = n_trials.matrix[i,j])
    
  }
}</code></pre>
<p> </p>
</div>
<div id="reshape-data" class="section level3">
<h3>Reshape data</h3>
<p>We now make use of the tidyverse set of packages. Data are reformatted from a wide format in which each mutant has its own column to <a href="https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html">tidy format</a>, which is easier to work with. In this long table format we have a single column to specify the mutant, and single columns for concentration, number of trials and number of successes. For convenience, we also tack on columns with the true mutant parameters (these values are simply repeated in each row for the same mutant). If you look at the ggplot function below, you will see the advantage that tidy format confers - we can now describe the plot for all mutants at once, rather than having to add layers for each mutant.</p>
<pre class="r"><code>library(reshape2)

# Use the melt function from reshape2, this is similar to tidyr&#39;s gather, but it also works on matrices and arrays.
# This converts data from wide to long format.
n_trials.frame &lt;- melt(n_trials.matrix)
colnames(n_trials.frame) &lt;- c(&quot;conc&quot;, &quot;mutant&quot;, &quot;n_trials&quot;)

prob.frame &lt;- melt(probability.matrix)
colnames(prob.frame) &lt;- c(&quot;conc&quot;, &quot;mutant&quot;, &quot;probability&quot;)

successes.frame &lt;- melt(successes.matrix)
colnames(successes.frame) &lt;- c(&quot;conc&quot;, &quot;mutant&quot;, &quot;successes&quot;)

detach(package:reshape2)

# Combine
experiment_data &lt;- left_join(successes.frame, n_trials.frame) %&gt;%
  left_join(prob.frame) %&gt;%
  left_join(mutant.frame)

#Trim away the zero readings.
experiment_data &lt;- experiment_data %&gt;%
  filter(conc &gt; centre - 4*width &amp; conc &lt; centre + 4*width)</code></pre>
<p> </p>
<p>And this is how our simulated measurements look:</p>
<pre class="r"><code># Plot
ggplot(experiment_data)+
  aes(x = conc, y = successes/n_trials, group = mutant)+
  geom_vline(data = mutant.frame, aes(xintercept = centre), linetype = &quot;dashed&quot;)+
  geom_line(aes(y = n_trials/max_trials), linetype = &quot;dashed&quot;, colour = &quot;grey&quot;)+
  geom_line(aes(y = probability), colour = &quot;blue&quot;)+
  geom_point(size = 1)+
  theme_bw(14)+
  facet_wrap(~mutant,ncol=2)+
  labs(x = &quot;Concentration&quot;, caption = paste0(&quot;Horizontal dashed line represents number of trials as fraction of maximum trials (&quot;, max_trials, &quot;).\nVertical dashed line shows the true centre.\nBlue curve shows the true probability.&quot;))</code></pre>
<p><img src="/post/Post_1_files/figure-html/plot_simulation-1.png" width="864" /></p>
<p> </p>
<hr />
<p> </p>
</div>
</div>
<div id="stan-model" class="section level2">
<h2>Stan model</h2>
<p>Here I use the tidy format data as the input. The mutants are named by an index rather than letter. All input data must be packaged together in a list.</p>
<pre class="r"><code>mlist &lt;- data.frame(&quot;mutant&quot; = mutants, mutant_num = seq(1:n_mutants))

experiment_data &lt;- experiment_data %&gt;% left_join(mlist)

dat_allmutants = list(
  J = n_mutants,
  N = nrow(experiment_data),
  mutant = experiment_data$mutant_num,
  x = experiment_data$conc,
  n_trials = experiment_data$n_trials,
  y = experiment_data$successes
)</code></pre>
<p> </p>
<p>The stan model is stored in a separate .stan file, however, it is also possible to provide it as a string. It is split into blocks as follows, shown individually for convenience. See the Stan manual for more information.</p>
<div id="data-block" class="section level3">
<h3>Data block</h3>
<pre class="cpp"><code>data {
  int&lt;lower=1&gt; J; //number of mutants
  int&lt;lower=1&gt; N; //Number of observations
  int&lt;lower=1,upper=J&gt; mutant[N]; //mutant for observation n
  vector[N] x; //concentration for observation n
  int&lt;lower=0&gt; n_trials[N]; //number of trials for observation n
  int&lt;lower=0&gt; y[N]; //Number of survivors for observation n
}
</code></pre>
<p>Values in the data block should match what we have put in our data list. The choice of type for each variable in the data block is crucial, and the Stan manual is very helpful in this area.</p>
</div>
<div id="parameters-block" class="section level3">
<h3>Parameters block</h3>
<pre class="cpp"><code>parameters {
  real mu_centre;
  real&lt;lower=0&gt; sigma_centre;
  vector[J] centre_raw;

  real mu_heightlogodds;
  real&lt;lower=0&gt; sigma_heightlogodds;
  vector[J] heightlogodds_raw;

  real&lt;lower=0&gt; mu_width_squared;
  real&lt;lower=0&gt; sigma_width_squared;
  vector[J] width_raw_squared;
}</code></pre>
<p>These are the parameters to be estimated by the regression fit. The parameters for each mutant are loosely treated as coming from common distributions. A population centre value is estimated, along with a scaling value. Individual mutant deviations are then drawn from centred unit normals. The mutant parameter is then given in the transformed parameters block as the mutant deviation times the scaling factor plus the population centre value. This is the non-centred parameterisation, which helps to avoid sampling problems when there are only a few members in the group. By contrast, in the centred parameterisation, individual mutant parameters would be drawn directly from a distribution with an estimated population centre and standard deviation.</p>
<p>Note that because the width parameter only appears as its square in the gaussian formula, it is simplified to width_squared here.</p>
</div>
<div id="transformed-parameters-block" class="section level3">
<h3>Transformed parameters block</h3>
<pre class="cpp"><code>transformed parameters {
  vector[J] height;
  vector[J] centre;
  vector[J] heightlogodds;
  vector&lt;lower=0&gt;[J] width_squared;

  centre = mu_centre + sigma_centre*centre_raw;

  heightlogodds = mu_heightlogodds + sigma_heightlogodds * heightlogodds_raw;

  height = inv_logit(heightlogodds);

  width_squared = mu_width_squared + sigma_width_squared * width_raw_squared;
}</code></pre>
<p>Here, individual centre, height and width_squared values for each mutant are calculated as the population centre value plus the individual mutant’s deviation times the scaling factor.</p>
</div>
<div id="model-block" class="section level3">
<h3>Model block</h3>
<pre class="cpp"><code>model {
  vector[N] psurvive;
  for (n in 1:N)
    psurvive[n] = height[mutant[n]] * exp( -0.5* ( ((x[n] - centre[mutant[n]])^2) / (width_squared[mutant[n]]) ) );

  mu_centre ~ normal(65,20); 
  sigma_centre ~ cauchy(0,10);
  centre_raw ~ normal(0,1);

  mu_heightlogodds ~ normal(0.5,2);
  sigma_heightlogodds ~ cauchy(0,2);
  heightlogodds_raw ~ normal(0,1);

  mu_width_squared ~ cauchy(0,5);
  sigma_width_squared ~ cauchy(0,3);
  width_raw_squared ~ normal(0,1);

  y ~ binomial(n_trials, psurvive);
}</code></pre>
<p>Prior probability distributions are specified for each parameter, as well as the likelihood. The likelihood is given by ‘y ~ binomial(n_trials, psurvive)’ in conjunction with the loop that gives psurvive values at each mutant/concentration combination.</p>
</div>
<div id="generated-quantities-block" class="section level3">
<h3>Generated quantities block</h3>
<pre class="cpp"><code>generated quantities {

  vector&lt;lower=0&gt;[J] width;
  width = sqrt(width_squared);
}</code></pre>
<p>Here, the width is output as the square root of the width_squared parameter. This, along with anything else that we might put in this block, is output purely for convenience, and is not part of the fitting process.</p>
<p> </p>
<hr />
<p> </p>
</div>
<div id="run-the-model" class="section level3">
<h3>Run the model</h3>
<p>In this case, the model is very fast. The slowest parts are compiling the model, and finding initial values that do not conflict with the parameter restrictions (e.g. non-negative values of width_squared). But it still only takes about 20 seconds in total, including 4.5 seconds of actual sampling. If this had been too much of a problem, it is possible to specify initial values (different values must be supplied to each chain). In my experience, having two or three grouping variables and <span class="math inline">\(10^4\)</span>-<span class="math inline">\(10^5\)</span> observations means that the model could take hours or tens of hours to fit.</p>
<pre class="r"><code>post_warmup &lt;- 2000
warmup_draws &lt;- 1000
n_chains &lt;- 4

fit &lt;- stan(file = &quot;mutant_model.stan&quot;, 
            model_name = &quot;example&quot;,
            data = dat_allmutants, 
            iter = post_warmup + warmup_draws, 
            warmup = warmup_draws, 
            chains = n_chains, 
            cores = 4,
            verbose = FALSE)</code></pre>
<p> </p>
<p>I am not going to devote the space here to investigating how well the model ran - convergence etc., but I will recommend that Shinystan is an excellent package for exploring these issues.</p>
<pre class="r"><code>library(shinystan)
launch_shinystan(fit)</code></pre>
<p> </p>
<p>The mutant centre values have turned out quite reasonable.</p>
<pre class="r"><code>plot(fit, pars = &quot;centre&quot;)</code></pre>
<p><img src="/post/Post_1_files/figure-html/plot_centre-1.png" width="864" /></p>
<p>Most pairs of mutants are distinct, however, some are overlapping. We will need to delve further into the posterior draws to assess these.</p>
<p> </p>
<hr />
<p> </p>
</div>
</div>
<div id="posterior-draws" class="section level2">
<h2>Posterior draws</h2>
<p>Extract some example posterior draws (note that these start from the first post-warmup draw) and calculate the corresponding probability curves given by the parameters in each draw. To get nice looking curves we will sample concentrations at finer intervals than we did in our experiment. Note that the package Bayesplot can do all of this (including supplying a custom function of the parameters, such as the gaussian), but for the sake of learning I have gone through this manually.</p>
<pre class="r"><code>n_draws &lt;- 200

draws &lt;- paste0(&quot;draw_&quot;, 1:n_draws)

list_of_draws &lt;- extract(fit, pars = c(&quot;centre&quot;, &quot;height&quot;, &quot;width&quot;))

centrevals &lt;- as.data.frame(list_of_draws$centre[1:n_draws,])
colnames(centrevals) &lt;- mutants

widthvals &lt;- as.data.frame(list_of_draws$width[1:n_draws,])
colnames(widthvals) &lt;- mutants

heightvals &lt;- as.data.frame(list_of_draws$height[1:n_draws,])
colnames(heightvals) &lt;- mutants

conc_detailed &lt;- seq(60,80,0.1)

#Create a 3D array of draw-mutant-concentration, filled with the probability of success.
curves &lt;- array(NA, dim=c(n_draws, n_mutants, length(conc_detailed)), 
                dimnames = list(draws, mutants, conc_detailed))
for (i in 1:n_draws){
  for (j in 1:n_mutants){
    for (k in 1:length(conc_detailed)){
      curves[i,j,k] &lt;- gaussian(height = heightvals[i,j], 
                                centre = centrevals[i,j], 
                                width = widthvals[i,j], 
                                x = conc_detailed[k]) 
    }
  }
}

#Turn the array into a data frame in tidy format - the fastest way is to use the melt function from reshape2 (unfortunately tidyr&#39;s &#39;gather&#39; does not work on arrays)
library(reshape2)
curves_c &lt;- melt(curves)
detach(package:reshape2)

colnames(curves_c) &lt;- c(&quot;draw&quot;, &quot;mutant&quot;, &quot;conc&quot;, &quot;prob&quot;)</code></pre>
<p> </p>
<p>Here are some functions to plot the posterior draws.</p>
<pre class="r"><code># A function from stack exchange by akrun that gives comma separated lists, with an &#39;and&#39; before the final item.
fPaste &lt;- function(vec) sub(&quot;,\\s+([^,]+)$&quot;, &quot; and \\1&quot;, toString(vec)) 

# A function to plot some draws in separate facets

compare_mutants_plot &lt;- function(mutantlist, draws_to_plot=12, centre_draws = centrevals, curvedata = curves_c){
  
  centrepositions &lt;- centre_draws[1:draws_to_plot,] %&gt;%
  mutate(draw = draws[1:draws_to_plot]) %&gt;%
  gather(mutant, centre,-draw)
  
  outplot &lt;- curvedata %&gt;%
  filter(mutant %in% mutantlist) %&gt;%
  filter(draw %in% draws[1:draws_to_plot]) %&gt;%
  ggplot()+
  aes(x = conc, y = prob, group = mutant, colour = mutant)+
  geom_line()+
  geom_vline(data = centrepositions %&gt;% 
               filter(mutant %in% mutantlist), 
             aes(xintercept = centre, colour = mutant))+
  facet_wrap(~draw)+
  scale_colour_manual(values = c(&quot;blue&quot;, &quot;darkorange&quot;))+
  labs(title = paste0(&quot;Fitted curves for mutants &quot;, fPaste(mutantlist), &quot;: &quot;, draws_to_plot, &quot; posterior draws&quot;),
       x = &quot;Concentration&quot;, 
       y = &quot;Probability of success&quot;)+
  theme(legend.position = &quot;bottom&quot;)
  
  return(outplot)
}

# A function to overlay many draws

overlay_mutants_plot &lt;- function(mutantlist, draws_to_plot=200, curvedata = curves_c){
  outplot &lt;- curvedata %&gt;%
    filter(mutant %in% mutantlist) %&gt;%
  ggplot()+
    aes(x = conc, y = prob, group = interaction(mutant, draw), colour = mutant)+
    geom_line(alpha = 0.3)+
    scale_colour_manual(values = c(&quot;blue&quot;, &quot;darkorange&quot;))+
    labs(title = paste0(&quot;Fitted curves for mutants &quot;, fPaste(mutantlist), &quot;: &quot;, draws_to_plot, &quot; posterior draws&quot;), 
         x = &quot;Concentration&quot;, 
         y = &quot;Probability of success&quot;)+
    theme(legend.position = &quot;bottom&quot;)
  return(outplot)
}

# A function to plot the distribution of differences between centre values
difference_plot &lt;- function(first_mutant = &quot;A&quot;, second_mutant = &quot;C&quot;, parameter = &quot;centre&quot;, drawlist = list_of_draws){
  
  first = match(first_mutant, mutants)
  second = match(second_mutant, mutants)
  
  first_mutant_draws &lt;- drawlist[[parameter]][,first]
  second_mutant_draws &lt;- drawlist[[parameter]][,second]
  
  outplot &lt;- data.frame(&quot;difference&quot; = first_mutant_draws - second_mutant_draws) %&gt;%
  ggplot()+
  aes(x = difference)+
  stat_density(geom = &quot;line&quot;, colour = &quot;blue&quot;)+
    labs(title = paste0(&quot;Distribution of differences of mutants &quot;, first_mutant, &quot; and &quot;, second_mutant, &quot; &quot;, parameter, &quot; values: &quot;, post_warmup*n_chains, &quot; posterior draws&quot;), 
         x = &quot;Difference&quot;)
  
  return(outplot)
  }</code></pre>
<p> </p>
<div id="mutants-a-and-c" class="section level3">
<h3>Mutants A and C</h3>
<p>Notably, from the plot above we can see that mutants A and C have partially overlapping distributions. Does this mean our model is implying that A and C could possibly share the same (or a very very close) value for centre? Not necessarily - to be able to make a statement about this we need to make comparisons within draws only. Let’s get a quick idea of how these look:</p>
<pre class="r"><code>compare_mutants_plot(c(&quot;A&quot;, &quot;C&quot;), 12)</code></pre>
<p><img src="/post/Post_1_files/figure-html/a_c_facet-1.png" width="864" /></p>
<p>But that was just a few draws, here are many more:</p>
<pre class="r"><code>overlay_mutants_plot(c(&quot;A&quot;, &quot;C&quot;))</code></pre>
<p><img src="/post/Post_1_files/figure-html/a_c_overlay-1.png" width="864" /></p>
<p>But this is still only a subset of the draws. We have done thousands more post-warmup draws, let’s compare across all of them. Mutant A appears to have a slightly higher peak centre value. In what fraction of draws is the peak centre of mutant A at a higher concentration than the peak centre of mutant C?</p>
<pre class="r"><code>centre_a.all &lt;- list_of_draws$centre[,1]
centre_c.all &lt;- list_of_draws$centre[,3]

sum(centre_a.all &gt; centre_c.all)/length(centre_a.all)</code></pre>
<pre><code>## [1] 0.97125</code></pre>
<p>97.1% of them. So, while we can see that they have very close centre values, mutant A probably has a greater centre value than mutant C. Indeed, we know that the true centre value for mutant A is 1.0 concentration units greater than that of C. We can go one better still, and plot the distribution of their differences in all draws.</p>
<pre class="r"><code>difference_plot(&quot;A&quot;, &quot;C&quot;)</code></pre>
<p><img src="/post/Post_1_files/figure-html/unnamed-chunk-8-1.png" width="864" /></p>
<p>The median difference is 0.9, a slight underestimate. Looking at the experimental data, there is one concentration point for mutant A to the left of its peak centre value at which an unusually high number of trials were successful, given the underlying probability. This would have the effect of dragging the estimated peak centre to the left. So we are within a regime where we get pretty good estimates, but are of course subject to stochasticity and a bit more data would help. The important point here is that we now have in hand a probability distribution for the difference between these values, rather than a single maximum likelihood estimation, which given the stochastic relationship between paramaters and observations is vastly preferable.</p>
<p> </p>
</div>
<div id="mutants-e-and-f" class="section level3">
<h3>Mutants E and F</h3>
<p>What about mutants E and F? The distributions for their centre values are entirely overlapping, and we know that their true centre values are identical.</p>
<pre class="r"><code>compare_mutants_plot(c(&quot;E&quot;, &quot;F&quot;), 12)</code></pre>
<p><img src="/post/Post_1_files/figure-html/e_f_facet-1.png" width="864" /></p>
<pre class="r"><code>overlay_mutants_plot(c(&quot;E&quot;, &quot;F&quot;))</code></pre>
<p><img src="/post/Post_1_files/figure-html/e_f_overlay-1.png" width="864" /></p>
<p>In what fraction of draws is the peak centre of mutant F at a lower concentration than the peak centre of mutant E?</p>
<pre class="r"><code>centre_e.all &lt;- list_of_draws$centre[,5]
centre_f.all &lt;- list_of_draws$centre[,6]

sum(centre_f.all &lt; centre_e.all)/length(centre_f.all)</code></pre>
<pre><code>## [1] 0.439125</code></pre>
<p>Mutant F, which is has a true peak centre identical to mutant E was lower than mutant E in approximately half of the draws, so we would not say that there is evidence they differ.</p>
<pre class="r"><code>difference_plot(&quot;E&quot;, &quot;F&quot;)</code></pre>
<p><img src="/post/Post_1_files/figure-html/unnamed-chunk-9-1.png" width="864" /></p>
<p> </p>
<p>So, the numbers are reasonable and the model is looking good, it did a good job with the simulated data. The next step would be to fit it to the actual experimental data.</p>
<p> </p>
<hr />
<p> </p>
</div>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/stan/">Stan</a>
  
  <a class="badge badge-light" href="/tags/regression/">regression</a>
  
</div>




    
    

    

    <div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://frhill.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/tex.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/c&#43;&#43;.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//frhill.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    
    

    
    

    

  </body>
</html>

