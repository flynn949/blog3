<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>multilevel modelling on Flynn R Hill</title>
    <link>/tags/multilevel-modelling/</link>
    <description>Recent content in multilevel modelling on Flynn R Hill</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Mon, 26 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/multilevel-modelling/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Multilevel logistic regression (again)</title>
      <link>/post/multilevel-logistic-regression/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/multilevel-logistic-regression/</guid>
      <description>I recently attended a whole-day workshop on multilevel modelling organised by NIASRA and taught by Professor Mark Tranmer, who is an expert in the field from the University of Glasgow.
One part of the workshop that I realised I didnâ€™t have any familiarity with was the idea of how variance works in logistic regression, and in particular in a multilevel logistic regression.
Here is one way of looking at logistic regression, in a formulation that reflects how a glm works:</description>
    </item>
    
  </channel>
</rss>